{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cordless-gnome",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install gensim\n",
    "# !pip install python-Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "conceptual-transcription",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\raghav.aggarwal\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "still-saver",
   "metadata": {},
   "source": [
    "### Reading and Exploring the Dataset\n",
    "The dataset we are using here is a subset of Amazon reviews from the Cell Phones & Accessories category. The data is stored as a JSON file and can be read using pandas.\n",
    "\n",
    "Link to the Dataset: http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Cell_Phones_and_Accessories_5.json.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "residential-people",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File Cell_Phones_and_Accessories_5.json does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_json(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCell_Phones_and_Accessories_5.json\u001b[39m\u001b[38;5;124m\"\u001b[39m, lines\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      2\u001b[0m df\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\io\\json\\_json.py:791\u001b[0m, in \u001b[0;36mread_json\u001b[1;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, precise_float, date_unit, encoding, encoding_errors, lines, chunksize, compression, nrows, storage_options, dtype_backend, engine)\u001b[0m\n\u001b[0;32m    788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_axes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m orient \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtable\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    789\u001b[0m     convert_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 791\u001b[0m json_reader \u001b[38;5;241m=\u001b[39m JsonReader(\n\u001b[0;32m    792\u001b[0m     path_or_buf,\n\u001b[0;32m    793\u001b[0m     orient\u001b[38;5;241m=\u001b[39morient,\n\u001b[0;32m    794\u001b[0m     typ\u001b[38;5;241m=\u001b[39mtyp,\n\u001b[0;32m    795\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m    796\u001b[0m     convert_axes\u001b[38;5;241m=\u001b[39mconvert_axes,\n\u001b[0;32m    797\u001b[0m     convert_dates\u001b[38;5;241m=\u001b[39mconvert_dates,\n\u001b[0;32m    798\u001b[0m     keep_default_dates\u001b[38;5;241m=\u001b[39mkeep_default_dates,\n\u001b[0;32m    799\u001b[0m     precise_float\u001b[38;5;241m=\u001b[39mprecise_float,\n\u001b[0;32m    800\u001b[0m     date_unit\u001b[38;5;241m=\u001b[39mdate_unit,\n\u001b[0;32m    801\u001b[0m     encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[0;32m    802\u001b[0m     lines\u001b[38;5;241m=\u001b[39mlines,\n\u001b[0;32m    803\u001b[0m     chunksize\u001b[38;5;241m=\u001b[39mchunksize,\n\u001b[0;32m    804\u001b[0m     compression\u001b[38;5;241m=\u001b[39mcompression,\n\u001b[0;32m    805\u001b[0m     nrows\u001b[38;5;241m=\u001b[39mnrows,\n\u001b[0;32m    806\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m    807\u001b[0m     encoding_errors\u001b[38;5;241m=\u001b[39mencoding_errors,\n\u001b[0;32m    808\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    809\u001b[0m     engine\u001b[38;5;241m=\u001b[39mengine,\n\u001b[0;32m    810\u001b[0m )\n\u001b[0;32m    812\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize:\n\u001b[0;32m    813\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m json_reader\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\io\\json\\_json.py:904\u001b[0m, in \u001b[0;36mJsonReader.__init__\u001b[1;34m(self, filepath_or_buffer, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, precise_float, date_unit, encoding, lines, chunksize, compression, nrows, storage_options, encoding_errors, dtype_backend, engine)\u001b[0m\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m filepath_or_buffer\n\u001b[0;32m    903\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mujson\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 904\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_data_from_filepath(filepath_or_buffer)\n\u001b[0;32m    905\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preprocess_data(data)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\io\\json\\_json.py:960\u001b[0m, in \u001b[0;36mJsonReader._get_data_from_filepath\u001b[1;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[0;32m    952\u001b[0m     filepath_or_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n\u001b[0;32m    953\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[0;32m    954\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(filepath_or_buffer, \u001b[38;5;28mstr\u001b[39m)\n\u001b[0;32m    955\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m filepath_or_buffer\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39mendswith(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    958\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m file_exists(filepath_or_buffer)\n\u001b[0;32m    959\u001b[0m ):\n\u001b[1;32m--> 960\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath_or_buffer\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not exist\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    961\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    962\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    963\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing literal json to \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mread_json\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is deprecated and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    964\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwill be removed in a future version. To read from a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    967\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    968\u001b[0m     )\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: File Cell_Phones_and_Accessories_5.json does not exist"
     ]
    }
   ],
   "source": [
    "df = pd.read_json(\"Cell_Phones_and_Accessories_5.json\", lines=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parliamentary-relations",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sensitive-peoples",
   "metadata": {},
   "source": [
    "### Simple Preprocessing & Tokenization\n",
    "The first thing to do for any data science task is to clean the data.\n",
    "For NLP, we apply various processing like converting all the words to lower case, trimming spaces, removing punctuations. \n",
    "This is something we will do over here too.\n",
    "\n",
    "Additionally, we can also remove stop words like 'and', 'or', 'is', 'the', 'a', 'an' and convert words to their root forms like 'running' to 'run'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informational-power",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_text = df.reviewText.apply(gensim.utils.simple_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flush-courtesy",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chief-postage",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_text.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "helpful-navigation",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reviewText.loc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "engaging-yorkshire",
   "metadata": {},
   "source": [
    "### Training the Word2Vec Model\n",
    "\n",
    "Train the model for reviews. Use a window of size 10 i.e. 10 words before the present word and 10 words ahead. A sentence with at least 2 words should only be considered, configure this using min_count parameter.\n",
    "\n",
    "Workers define how many CPU threads to be used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civic-links",
   "metadata": {},
   "source": [
    "#### Initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "determined-disclosure",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec(\n",
    "    window=10,\n",
    "    min_count=2,\n",
    "    workers=4,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "olympic-manner",
   "metadata": {},
   "source": [
    "#### Build Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "juvenile-dubai",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build_vocab(review_text, progress_per=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pharmaceutical-adoption",
   "metadata": {},
   "source": [
    "#### Train the Word2Vec Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adopted-kentucky",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(review_text, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brave-bullet",
   "metadata": {},
   "source": [
    "### Save the Model\n",
    "\n",
    "Save the model so that it can be reused in other applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "following-pizza",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./word2vec-amazon-cell-accessories-reviews-short.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "creative-convert",
   "metadata": {},
   "source": [
    "### Finding Similar Words and Similarity between words\n",
    "https://radimrehurek.com/gensim/models/word2vec.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "legislative-bearing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('terrible', 0.6617082357406616),\n",
       " ('horrible', 0.6136840581893921),\n",
       " ('crappy', 0.5805919170379639),\n",
       " ('good', 0.5770503878593445),\n",
       " ('shabby', 0.5749340653419495),\n",
       " ('awful', 0.5492298007011414),\n",
       " ('ok', 0.5294141173362732),\n",
       " ('cheap', 0.5288074612617493),\n",
       " ('legit', 0.5199155807495117),\n",
       " ('okay', 0.5171135663986206)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"bad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "sacred-mathematics",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.52680796"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity(w1=\"cheap\", w2=\"inexpensive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "described-smile",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7714366"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity(w1=\"great\", w2=\"good\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hollywood-beverage",
   "metadata": {},
   "source": [
    "### Further Reading\n",
    "\n",
    "You can read about gensim more at https://radimrehurek.com/gensim/models/word2vec.html\n",
    "\n",
    "Explore other Datasets related to Amazon Reviews: http://jmcauley.ucsd.edu/data/amazon/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "physical-defensive",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Train a word2vec model on the [Sports & Outdoors Reviews Dataset](http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Sports_and_Outdoors_5.json.gz)\n",
    "Once you train a model on this, find the words most similar to 'awful' and find similarities between the following word tuples: ('good', 'great'), ('slow','steady')\n",
    "\n",
    "Click here for [solution](https://github.com/codebasics/deep-learning-keras-tf-tutorial/blob/master/42_word2vec_gensim/42_word2vec_gensim_exercise_solution.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
